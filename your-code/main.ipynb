{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "\n",
    "Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics.\n",
    "\n",
    "We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's pick one entry and see what number is written. Use indexing to pick the 35th digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use the *reshape(28,28)* method and *plt.imshow()* function with the parameters *cmap = matplotlib.cm.binary* and *interpolation=\"nearest\"* to make a plot of the number. Be sure to import matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T = np.reshape(X[35], (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x125b405b0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_T, cmap = matplotlib.cm.binary, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 35th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  29., 141., 198., 255., 198.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  86., 141., 198., 255., 255., 255., 255.,\n",
       "       170.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29., 141., 226., 255.,\n",
       "       255., 255., 255., 198.,  86.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 170., 255., 255., 170.,  86.,  86.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 141., 226., 170.,  57.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  86., 255., 198.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 198., 255., 141.,  86.,\n",
       "        57.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 170., 255., 198., 114., 226., 170.,  29.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  57., 198., 255., 114.,  29.,   0.,\n",
       "       141., 255.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       114., 255., 114.,   0.,   0.,   0., 141., 255.,  29.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29.,   0.,   0.,   0.,\n",
       "         0., 226., 255.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 114., 255., 141.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  86.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       114., 226., 226.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255., 198.,\n",
       "        86.,   0.,   0.,   0., 141., 255., 255., 170.,  29.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 226., 255., 226., 170., 226., 255., 255.,\n",
       "       198.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  86.,\n",
       "       198., 255., 255., 170., 141.,  57.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = np.where(y_train == \"5\", 1, 0)\n",
    "y_test_5 = np.where(y_test == \"5\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression to predict if a number is a 5 or not. Remember to use the 'just 5s' target train array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9034,   74],\n",
       "       [ 147,  745]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "model = clf.fit(X_train, y_train_5)\n",
    "y_test_5_predict = model.predict(X_test)\n",
    "confusion_matrix(y_test_5, y_test_5_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the classifier predict correctly the 35th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "model = clf.fit(X_train, y_train_5)\n",
    "y_train_5_predict = model.predict(X_train)\n",
    "y_train_5_predict[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Yes, it predicts it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 36000th value is a 9. Check if it was correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[52998,  1053],\n",
       "       [ 1173,  4776]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_9 = np.where(y_train == \"9\", 1, 0)\n",
    "y_test_9 = np.where(y_test == \"9\", 1, 0)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "model = clf.fit(X_train, y_train_9)\n",
    "y_9_train_predict = model.predict(X_train)\n",
    "\n",
    "y_9_train_predict[36000] \n",
    "confusion_matrix(y_train_9, y_9_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1))[:, 0]\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit and predict on the testing set using our dumb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_never5_pred = never_5_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9108    0]\n",
      " [ 892    0]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# CLF NEVER5 SCORES\n",
    "from sklearn.metrics import precision_score\n",
    "confusion_matrix_never5 = confusion_matrix(y_test_5, y_never5_pred) \n",
    "print(confusion_matrix_never5)\n",
    "\n",
    "f1_score_never5 = f1_score(y_test_5, y_never5_pred)\n",
    "print(f1_score_never5)\n",
    "\n",
    "average_precision_never5 = precision_score(y_test_5, y_never5_pred)\n",
    "print(average_precision_never5)\n",
    "\n",
    "recall_score_never5 = recall_score(y_test_5, y_never5_pred)\n",
    "print(recall_score_never5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As expected, the recall dummy classifier has very low scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54153   426]\n",
      " [  905  4516]]\n",
      "0.871562288912477\n",
      "0.9138000809388911\n",
      "0.8330566316177827\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_5 = confusion_matrix(y_train_5, y_train_5_predict)\n",
    "print(confusion_matrix_5)\n",
    "\n",
    "f1_score_5 = f1_score(y_train_5, y_train_5_predict)\n",
    "print(f1_score_5)\n",
    "\n",
    "average_precision_5 = precision_score(y_train_5, y_train_5_predict)\n",
    "print(average_precision_5)\n",
    "\n",
    "recall_score_5 = recall_score(y_train_5, y_train_5_predict)\n",
    "print(recall_score_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The logistic regression works very well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> They indicate how close is our predicted target to the true ground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([0., 1.]), array([1., 0.]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve(y_test_5, y_never5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.       , 0.0078052, 1.       ]),\n",
       " array([0.        , 0.83305663, 1.        ]),\n",
       " array([2, 1, 0]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve(y_train_5, y_train_5_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
